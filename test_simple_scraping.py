#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
ì´ì „ ë°©ì‹ìœ¼ë¡œ ë˜ëŒë ¤ì„œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.scraper.naver import NaverScraper

def test_simple_scraping():
    """ê°„ë‹¨í•œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ê°„ë‹¨í•œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    scraper = NaverScraper("sessions", "snapshots")
    
    try:
        # 1. ë¸Œë¼ìš°ì € ì‹œì‘
        print("1ï¸âƒ£ ë¸Œë¼ìš°ì € ì‹œì‘")
        scraper.start_browser()
        
        # 2. ì¿ í‚¤ ë¡œë“œ
        print("2ï¸âƒ£ ì¿ í‚¤ ë¡œë“œ")
        scraper._load_cookies()
        
        # 3. ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
        print("3ï¸âƒ£ ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸")
        if not scraper._check_login_status():
            print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
            return
        
        # 4. ì¹´í˜ ì ‘ì†
        print("4ï¸âƒ£ ì¹´í˜ ì ‘ì†")
        cafe_url = "https://cafe.naver.com/sundreamd"
        scraper.driver.get(cafe_url)
        time.sleep(3)
        
        # 5. ê²Œì‹œíŒ ëª©ë¡ ì¡°íšŒ
        print("5ï¸âƒ£ ê²Œì‹œíŒ ëª©ë¡ ì¡°íšŒ")
        boards = scraper.get_cafe_boards(cafe_url)
        print(f"âœ… ê²Œì‹œíŒ {len(boards)}ê°œ ì¡°íšŒ")
        
        # 6. â˜…ê°€ì…ì¸ì‚¬ ê²Œì‹œíŒ ì°¾ê¸°
        target_board = None
        for board in boards:
            if board['menu_name'] == 'â˜…ê°€ì…ì¸ì‚¬':
                target_board = board
                break
        
        if not target_board:
            print("âŒ â˜…ê°€ì…ì¸ì‚¬ ê²Œì‹œíŒ ì—†ìŒ")
            return
        
        print(f"âœ… ëŒ€ìƒ ê²Œì‹œíŒ: {target_board['menu_name']}")
        
        # 7. ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ (1í˜ì´ì§€ë§Œ)
        print("7ï¸âƒ£ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘")
        board_results = scraper.scrape_board_articles(target_board['board_url'], max_pages=1)
        print(f"âœ… ê²Œì‹œê¸€ {len(board_results)}ê°œ ë°œê²¬")
        
        if not board_results:
            print("âŒ ê²Œì‹œê¸€ ì—†ìŒ")
            return
        
        # 8. ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘
        print("8ï¸âƒ£ ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘")
        first_article = board_results[0]
        print(f"ğŸ“„ ì œëª©: {first_article.get('title', 'N/A')}")
        print(f"ğŸ”— URL: {first_article.get('article_url', 'N/A')}")
        
        try:
            detailed_result = scraper.scrape_article(first_article['article_url'])
            print("âœ… ìƒì„¸ ìŠ¤í¬ë˜í•‘ ì„±ê³µ")
            print(f"ğŸ“ ë‚´ìš© ê¸¸ì´: {len(detailed_result.get('content_text', ''))}")
            print(f"ğŸ’¬ ëŒ“ê¸€ ìˆ˜: {len(detailed_result.get('comments', []))}")
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜: {len(detailed_result.get('images_base64', []))}")
            
        except Exception as e:
            print(f"âŒ ìƒì„¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ ê°„ë‹¨í•œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ë¸Œë¼ìš°ì € ì¢…ë£Œ
        if scraper.driver:
            scraper.close()
            print("ğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œë¨")

if __name__ == "__main__":
    test_simple_scraping()

